{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b0e11f2-9ea4-48c2-b8d2-d0a4ba967827",
   "metadata": {},
   "source": [
    "# Gradio Day!\n",
    "\n",
    "Today we will build User Interfaces using the outrageously simple Gradio framework.\n",
    "\n",
    "Prepare for joy!\n",
    "\n",
    "Please note: your Gradio screens may appear in 'dark mode' or 'light mode' depending on your computer settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05324a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gradio\n",
      "  Downloading gradio-6.4.0-py3-none-any.whl (24.3 MB)\n",
      "     --------------------------------------- 24.3/24.3 MB 18.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\vedanth\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (25.0)\n",
      "Requirement already satisfied: httpx<1.0,>=0.24.1 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (0.28.1)\n",
      "Collecting ffmpy\n",
      "  Downloading ffmpy-1.0.0-py3-none-any.whl (5.6 kB)\n",
      "Collecting brotli>=1.1.0\n",
      "  Downloading brotli-1.2.0-cp310-cp310-win_amd64.whl (369 kB)\n",
      "     ------------------------------------- 369.0/369.0 kB 11.6 MB/s eta 0:00:00\n",
      "Collecting tomlkit<0.14.0,>=0.12.0\n",
      "  Downloading tomlkit-0.13.3-py3-none-any.whl (38 kB)\n",
      "Collecting uvicorn>=0.14.0\n",
      "  Downloading uvicorn-0.40.0-py3-none-any.whl (68 kB)\n",
      "     ---------------------------------------- 68.5/68.5 kB 3.6 MB/s eta 0:00:00\n",
      "Collecting semantic-version~=2.0\n",
      "  Using cached semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.7\n",
      "  Downloading safehttpx-0.1.7-py3-none-any.whl (9.0 kB)\n",
      "Collecting groovy~=0.1\n",
      "  Downloading groovy-0.1.2-py3-none-any.whl (14 kB)\n",
      "Collecting typer<1.0,>=0.12\n",
      "  Downloading typer-0.21.1-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 47.4/47.4 kB 2.3 MB/s eta 0:00:00\n",
      "Collecting fastapi<1.0,>=0.115.2\n",
      "  Downloading fastapi-0.128.0-py3-none-any.whl (103 kB)\n",
      "     -------------------------------------- 103.1/103.1 kB 6.2 MB/s eta 0:00:00\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Collecting pandas<3.0,>=1.0\n",
      "  Downloading pandas-2.3.3-cp310-cp310-win_amd64.whl (11.3 MB)\n",
      "     --------------------------------------- 11.3/11.3 MB 28.5 MB/s eta 0:00:00\n",
      "Collecting pillow<13.0,>=8.0\n",
      "  Downloading pillow-12.1.0-cp310-cp310-win_amd64.whl (7.0 MB)\n",
      "     ---------------------------------------- 7.0/7.0 MB 14.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=0.33.5 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (1.3.2)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (4.12.1)\n",
      "Collecting python-multipart>=0.0.18\n",
      "  Downloading python_multipart-0.0.21-py3-none-any.whl (24 kB)\n",
      "Collecting aiofiles<25.0,>=22.0\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: pydantic<=3.0,>=2.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (2.12.5)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (6.0.3)\n",
      "Collecting numpy<3.0,>=1.0\n",
      "  Downloading numpy-2.2.6-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "     --------------------------------------- 12.9/12.9 MB 19.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\vedanth\\appdata\\roaming\\python\\python310\\site-packages (from gradio) (4.15.0)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (3.1.6)\n",
      "Requirement already satisfied: markupsafe<4.0,>=2.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (3.0.3)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Downloading starlette-0.52.1-py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 74.3/74.3 kB 4.0 MB/s eta 0:00:00\n",
      "Collecting gradio-client==2.0.3\n",
      "  Downloading gradio_client-2.0.3-py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.7/55.7 kB ? eta 0:00:00\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio) (3.11.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from gradio-client==2.0.3->gradio) (2026.1.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\vedanth\\appdata\\roaming\\python\\python310\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.11)\n",
      "Collecting annotated-doc>=0.0.2\n",
      "  Downloading annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
      "Collecting starlette<1.0,>=0.40.0\n",
      "  Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 74.0/74.0 kB 4.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (1.0.9)\n",
      "Requirement already satisfied: certifi in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpx<1.0,>=0.24.1->gradio) (2026.1.4)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from httpcore==1.*->httpx<1.0,>=0.24.1->gradio) (0.16.0)\n",
      "Requirement already satisfied: typer-slim in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (0.21.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (4.67.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (3.20.3)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.2.0)\n",
      "Requirement already satisfied: shellingham in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<2.0,>=0.33.5->gradio) (1.5.4)\n",
      "Collecting tzdata>=2022.7\n",
      "  Downloading tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "     ------------------------------------- 348.5/348.5 kB 21.1 MB/s eta 0:00:00\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "     ------------------------------------- 509.2/509.2 kB 10.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\vedanth\\appdata\\roaming\\python\\python310\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pydantic<=3.0,>=2.0->gradio) (0.4.2)\n",
      "Collecting rich>=10.11.0\n",
      "  Downloading rich-14.2.0-py3-none-any.whl (243 kB)\n",
      "     ------------------------------------- 243.4/243.4 kB 14.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\vedanth\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (8.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\vedanth\\appdata\\roaming\\python\\python310\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\vedanth\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\vedanth\\appdata\\roaming\\python\\python310\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "     ---------------------------------------- 87.3/87.3 kB 4.8 MB/s eta 0:00:00\n",
      "Collecting mdurl~=0.1\n",
      "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: pytz, pydub, brotli, tzdata, tomlkit, semantic-version, python-multipart, pillow, numpy, mdurl, groovy, ffmpy, annotated-doc, aiofiles, uvicorn, pandas, markdown-it-py, starlette, rich, typer, safehttpx, fastapi, gradio-client, gradio\n",
      "Successfully installed aiofiles-24.1.0 annotated-doc-0.0.4 brotli-1.2.0 fastapi-0.128.0 ffmpy-1.0.0 gradio-6.4.0 gradio-client-2.0.3 groovy-0.1.2 markdown-it-py-4.0.0 mdurl-0.1.2 numpy-2.2.6 pandas-2.3.3 pillow-12.1.0 pydub-0.25.1 python-multipart-0.0.21 pytz-2025.2 rich-14.2.0 safehttpx-0.1.7 semantic-version-2.10.0 starlette-0.50.0 tomlkit-0.13.3 typer-0.21.1 tzdata-2025.3 uvicorn-0.40.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.2.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c44c5494-950d-4d2f-8d4f-b87b57c5b330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1715421-cead-400b-99af-986388a97aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Vedanth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr # oh yeah!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337d5dfc-0181-4e3b-8ab9-e78e0c3f657b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key exists and begins sk-proj-\n",
      "Anthropic API Key not set\n",
      "Google API Key not set\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables in a file called .env\n",
    "# Print the key prefixes to help with any debugging\n",
    "# You can choose whichever providers you like - or all Ollama\n",
    "\n",
    "load_dotenv(override=True)\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22586021-1795-4929-8079-63f5bb4edd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to OpenAI, Anthropic and Google; comment out the Claude or Google lines if you're not using them\n",
    "\n",
    "openai = OpenAI()\n",
    "\n",
    "anthropic_url = \"https://api.anthropic.com/v1/\"\n",
    "gemini_url = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "\n",
    "anthropic = OpenAI(api_key=anthropic_api_key, base_url=anthropic_url)\n",
    "gemini = OpenAI(api_key=google_api_key, base_url=gemini_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02ef9b69-ef31-427d-86d0-b8c799e1c1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's wrap a call to GPT-4.1-mini in a simple function\n",
    "\n",
    "system_message = \"You are a helpful assistant\"\n",
    "\n",
    "def message_gpt(prompt):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}, {\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aef7d314-2b13-436b-b02d-8de3b72b193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Today's date is April 27, 2024.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This can reveal the \"training cut off\", or the most recent date in the training data\n",
    "\n",
    "message_gpt(\"What is today's date?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94013d1-4f27-4329-97e8-8c58db93636a",
   "metadata": {},
   "source": [
    "## User Interface time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc664b7a-c01d-4fea-a1de-ae22cdd5141a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's a simple function\n",
    "\n",
    "def shout(text):\n",
    "    print(f\"Shout has been called with input {text}\")\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "977bb496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shout has been called with input hello\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "083ea451-d3a0-4d13-b599-93ed49b975e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002ab4a6",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">NOTE: Using Gradio's Share tool</h2>\n",
    "            <span style=\"color:#900;\">I'm about to show you a really cool way to share your Gradio UI with others. This deploys your gradio app as a demo on gradio's website, and then allows gradio to call the 'shout' function. This uses an advanced technology known as 'HTTP tunneling' (like ngrok for people who know it) which isn't allowed by many Antivirus programs and corporate environments. If you get an error, just skip the next cell.<br/>\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9a359a4-685c-4c99-891c-bb4d1cb7f426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding share=True means that it can be accessed publically\n",
    "# A more permanent hosting is available using a platform called Spaces from HuggingFace, which we will touch on next week\n",
    "# NOTE: Some Anti-virus software and Corporate Firewalls might not like you using share=True. \n",
    "# If you're at work on on a work network, I suggest skip this test.\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cd87533a-ff3a-4188-8998-5bedd5ba2da3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding inbrowser=True opens up a new browser window automatically\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42945b17",
   "metadata": {},
   "source": [
    "## Adding authentication\n",
    "\n",
    "Gradio makes it very easy to have userids and passwords\n",
    "\n",
    "Obviously if you use this, have it look properly in a secure place for passwords! At a minimum, use your .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c34e6735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True, auth=(\"ved\", \"baliga\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42ec007-0314-48bf-84a4-a65943649215",
   "metadata": {},
   "source": [
    "## Forcing dark mode\n",
    "\n",
    "Gradio appears in light mode or dark mode depending on the settings of the browser and computer. There is a way to force gradio to appear in dark mode, but Gradio recommends against this as it should be a user preference (particularly for accessibility reasons). But if you wish to force dark mode for your screens, below is how to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8129afa-532b-4b15-b93c-aa9cca23a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define this variable and then pass js=force_dark_mode when creating the Interface\n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3cc67b26-dd5f-406d-88f6-2306ee2950c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7867\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding a little more:\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message to be shouted\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=shout,\n",
    "    title=\"Shout\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f235288e-63a2-4341-935b-1441f9be969b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And now - changing the function from \"shout\" to \"message_gpt\"\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
    "message_output = gr.Textbox(label=\"Response:\", lines=8)\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\"hello\", \"howdy\"], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af9a3262-e626-4e4b-80b0-aca152405e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7862/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's use Markdown\n",
    "# Are you wondering why it makes any difference to set system_message when it's not referred to in the code below it?\n",
    "# I'm taking advantage of system_message being a global variable, used back in the message_gpt function (go take a look)\n",
    "# Not a great software engineering practice, but quite common during Jupyter Lab R&D!\n",
    "\n",
    "system_message = \"You are a helpful assistant that responds in markdown without code blocks\"\n",
    "\n",
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=message_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88c04ebf-0671-4fea-95c9-bc1565d4bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a call that streams back results\n",
    "# If you'd like a refresher on Generators (the \"yield\" keyword),\n",
    "# Please take a look at the Intermediate Python guide in the guides folder\n",
    "\n",
    "def stream_gpt(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4.1-mini',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0bb1f789-ff11-4cba-ac67-11b815e29d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT-4.1-mini\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_gpt,\n",
    "    title=\"GPT\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bbc8e930-ba2a-4194-8f7c-044659150626",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gpt_2(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-5',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a0066ffd-196e-4eaf-ad1e-d492958b62af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for GPT 5\", lines=7)\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_gpt_2,\n",
    "    title=\"GPT 5\", \n",
    "    inputs=[message_input], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "        \"Explain the Transformer architecture to a layperson\",\n",
    "        \"Explain the Transformer architecture to an aspiring AI engineer\",\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5a70b9-2afe-4a7c-9bed-2429229e021b",
   "metadata": {},
   "source": [
    "## And now getting fancy\n",
    "\n",
    "Remember to check the Intermediate Python Guide if you're unsure about generators and \"yield\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0087623a-4e31-470b-b2e6-d8d16fc7bcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_model(prompt, model):\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_gpt_2(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8d8ce810-997c-4b6a-bc4f-1fc847ac8855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_input = gr.Textbox(label=\"Your message:\", info=\"Enter a message for the LLM\", lines=7)\n",
    "model_selector = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_model,\n",
    "    title=\"LLMs\", \n",
    "    inputs=[message_input, model_selector], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "            [\"Explain the Transformer architecture to a layperson\", \"GPT\"],\n",
    "            [\"Explain the Transformer architecture to an aspiring AI engineer\", \"Claude\"]\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933865b-654c-4b92-aa45-cf389f1eda3d",
   "metadata": {},
   "source": [
    "# Building a company brochure generator\n",
    "\n",
    "Now you know how - it's simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d7c49b-2e0e-45b3-92ce-93ca9f962ef4",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/important.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#900;\">Before you read the next few cells</h2>\n",
    "            <span style=\"color:#900;\">\n",
    "                Try to do this yourself - go back to the company brochure in week1, day5 and add a Gradio UI to the end. Then come and look at the solution.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1626eb2e-eee8-4183-bda5-1591b58ae3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scraper import fetch_website_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c701ec17-ecd5-4000-9f68-34634c8ed49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Again this is typical Experimental mindset - I'm changing the global variable we used above:\n",
    "\n",
    "system_message = \"\"\"\n",
    "You are an assistant that analyzes the contents of a company website landing page\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits.\n",
    "Respond in markdown without code blocks.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5def90e0-4343-4f58-9d4a-0e36e445efa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    yield \"\"\n",
    "    prompt = f\"Please generate a company brochure for {company_name}. Here is their landing page:\\n\"\n",
    "    prompt += fetch_website_contents(url)\n",
    "    if model==\"GPT\":\n",
    "        result = stream_gpt(prompt)\n",
    "    elif model==\"Claude\":\n",
    "        result = stream_claude(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66399365-5d67-4984-9d47-93ed26c0bd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_input = gr.Textbox(label=\"Company name:\")\n",
    "url_input = gr.Textbox(label=\"Landing page URL including http:// or https://\")\n",
    "model_selector = gr.Dropdown([\"GPT\", \"Claude\"], label=\"Select model\", value=\"GPT\")\n",
    "message_output = gr.Markdown(label=\"Response:\")\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    title=\"Brochure Generator\", \n",
    "    inputs=[name_input, url_input, model_selector], \n",
    "    outputs=[message_output], \n",
    "    examples=[\n",
    "            [\"Hugging Face\", \"https://huggingface.co\", \"GPT\"],\n",
    "            [\"Edward Donner\", \"https://edwarddonner.com\", \"Claude\"]\n",
    "        ], \n",
    "    flagging_mode=\"never\"\n",
    "    )\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611dd9c4",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left;\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/resources.jpg\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#f71;\">Gradio Resources</h2>\n",
    "            <span style=\"color:#f71;\">If you'd like to go deeper on Gradio, check out the amazing documentation - a wonderful rabbit hole.<br/>\n",
    "            <a href=\"https://www.gradio.app/guides/quickstart\">https://www.gradio.app/guides/quickstart</a><br/>Gradio is primarily designed for Demos, Prototypes and MVPs, but I've also used it frequently to make internal apps for power users.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
